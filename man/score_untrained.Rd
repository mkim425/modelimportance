% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/score_untrained.R
\name{score_untrained}
\alias{score_untrained}
\title{Calculate model importance for a single task when using an untrained
ensemble}
\usage{
score_untrained(
  single_task_data,
  oracle_output_data,
  model_id_list,
  ensemble_fun,
  importance_algorithm,
  subset_wt,
  metric,
  ...
)
}
\arguments{
\item{single_task_data}{A data.frame with the predictions for a single
forecast task in a model_out_tbl format. The data must contain only one
\code{output_type}, which must be one of the following:
\code{mean}, \code{median}, \code{quantile}, or \code{pmf}.}

\item{oracle_output_data}{Ground truth data for the variables that are used
to define modeling targets. This data must follow the oracle output format.
See 'Details'.}

\item{model_id_list}{A list of all component model IDs to be used in the
ensemble. If a model is not present in the \code{single_task_data}, it means that
the model did not submit predictions for the given task.
This list is used to identify missing models in the ensemble.}

\item{ensemble_fun}{A character string specifying a ensemble method, either
"simple_ensemble" or "linear_pool"; \code{c("simple_ensemble", "linear_pool")}.
\itemize{
\item When \code{"simple_ensemble"} is specified, the ensemble is generated using the
optional \code{agg_fun} function in \code{...} (see 'Details').
\item When \code{"linear_pool"} is specified, ensemble model outputs are created as
a linear pool of component model outputs. This method supports only
an \code{output_type} of \code{mean}, \code{quantile}, or \code{pmf}.
}}

\item{importance_algorithm}{A character string specifying algorithm for model
importance calculation; \code{c("lomo", "lasomo")}.
\code{"lomo"} stands for leave-one-model-out and
\code{"lasomo"} stands for leave all subsets of models out.}

\item{subset_wt}{A character string specifying method for assigning weight
to subsets when using \code{lasomo} algorithm; \code{c("equal", "perm_based")}.
\itemize{
\item \code{"equal"} assigns equal weight to all subsets.
\item \code{"perm_based"} assigns weight averaged over all possible permutations as in
the Shapley value.
}}

\item{metric}{A character string specifying the metric to be used for scoring
the model output. The metric is determined by the \code{output_type} and must be
one of the following: \code{se_point}, \code{ae_point}, \code{wis}, or \code{log_score}.}

\item{...}{Optional arguments passed to \code{ensemble_fun} when it is specified
as \code{"simple_ensemble"}. See 'Details'.}
}
\value{
A data.frame with columns
\code{task_id}, \code{output_type}, \code{model_id}, \code{task_level_importance}.
}
\description{
Evaluate the importance of ensemble component models by quantifying their
contribution to the prediction accuracy of an untrained ensemble for each
combination of model task.
}
\details{
The \code{oracle_output_data} in the oracle output format should contain
independent task ID columns (e.g. \code{location}, \code{target_date}, and \code{age_group})
, \code{output_type} and \code{output_type_id} columns if the output is either \code{pmf} or
\code{cdf}, and \code{oracle_value} column for the observed values.
TBD for more details.

Additional argument in \code{...} is \code{agg_fun}, which is a character string name
for a function specifying aggregation method of component model outputs.
Default is \code{mean}, meaning that equally (or weighted) mean is calculated
across all component model outputs for each unique \code{output_type_id}.
This can be \code{median} or a custom function (e.g., geometric_mean. Details
can be found in
https://hubverse-org.github.io/hubEnsembles/articles/hubEnsembles.html)
}
\examples{
\dontrun{
library(dplyr)
library(hubEnsembles)
library(hubEvals)
forecast_data <- hubExamples::forecast_outputs |>
  dplyr::filter(
    output_type \%in\% c("mean"),
    location == "25",
    horizon == 1
  )
target_data <- hubExamples::forecast_target_ts |>
  dplyr::filter(
    date \%in\% unique(forecast_data$target_end_date),
    location == "25"
  ) |>
  # Rename columns to match the oracle output format
  rename(
    target_end_date = date,
    oracle_value = observation
  )

valid_tbl <- validate_input_data(forecast_means, target_data)
all_models <- unique(valid_tbl$model_id)
list_datasets <- split_data_by_task(
  valid_tbl,
  weighted = FALSE,
  training_window_length = 0
)

# Example with the default arguments.
score_untrained(
  single_task_data = list_datasets[[1]], oracle_output_data = target_data,
  model_id_list = all_models, ensemble_fun = "simple_ensemble",
  importance_algorithm = "lomo", subset_wt = "equal", metric = "se_point"
)
# Example with the additional argument in `...`.
score_untrained(
  single_task_data = list_datasets[[1]], oracle_output_data = target_data,
  model_id_list = all_models, ensemble_fun = "simple_ensemble",
  importance_algorithm = "lomo", subset_wt = "equal", metric = "se_point",
  agg_fun = median
)
}
}
