% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model_importance_summary.R
\name{model_importance_summary}
\alias{model_importance_summary}
\title{Summarize model importance scores produced by \code{model_importance()}
across tasks}
\usage{
model_importance_summary(
  importance_scores,
  by = "model_id",
  na_action = c("drop", "worst", "average"),
  fun = mean,
  ...
)
}
\arguments{
\item{importance_scores}{A data frame containing model importance scores for
individual prediction tasks, as produced by the \code{model_importance()}
function. The data frame should include columns \code{model_id}, \code{reference_date},
any task ID columns (e.g., \code{location}, \code{horizon}, and \code{target_end_date}),
\code{output_type}, and \code{importance}.}

\item{by}{A character vector with column names specifying the grouping
variable(s) for summarization. Default is \code{"model_id"}, which summarizes
importance scores for each model across all tasks.}

\item{na_action}{A character string specifying how to handle \code{NA} values
generated during importance score calculation for each task, occurring when a
model did not contribute to the ensemble prediction for a given task by
missing its forecast submission.
Three options are available: \code{c("drop", "worst", "average")}.
For each specific prediction task, each option works as follows:
\itemize{
\item \code{"drop"} removes \code{NA}s.
\item \code{"worst"} replaces \code{NA}s with the smallest value among importance metrics
of the other models.
\item \code{"average"} replaces \code{NA}s with the average value from the other
models' importance metrics.
}}

\item{fun}{A function used to summarize importance scores.
Default is \code{mean()}}

\item{...}{Additional arguments passed to the summary function \code{fun}.
See the documentation of the corresponding function for details.}
}
\value{
A data.frame with columns \code{model_id} and \verb{importance_score_<fun>},
where \verb{<fun>} is the name of the summary function used
(e.g., \code{importance_score_mean} when \code{fun = mean}).
The output is sorted in descending order of the summary importance scores.
}
\description{
\code{model_importance_summary} summarizes model importance scores
calculated for individual prediction tasks into a summary statistic for
each model. This function handles \code{NA} values in importance scores generated
when a model did not contribute to the ensemble prediction for a given task
by missing its forecast submission.
}
\examples{
\dontrun{
library(dplyr)
library(hubExamples)
forecast_data <- hubExamples::forecast_outputs |>
  dplyr::filter(
    output_type \%in\% c("quantile"),
    location == "25",
    horizon == 1
  )
target_data <- hubExamples::forecast_target_ts |>
  dplyr::filter(
    date \%in\% unique(forecast_data$target_end_date),
    location == "25"
  ) |>
  # Rename columns to match the oracle output format
  rename(
    target_end_date = date,
    oracle_value = observation
  )
# Example with the default arguments.
importance_scores <- model_importance(
  forecast_data = forecast_data, oracle_output_data = target_data,
  ensemble_fun = "simple_ensemble", importance_algorithm = "lomo",
  subset_wt = "equal"
)
model_importance_summary(importance_scores, by = "model_id")
}
}
